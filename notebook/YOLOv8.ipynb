{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe9vkEvFABbN"
      },
      "source": [
        "# Probe Detection Using Deep Learning\n",
        "---\n",
        "\n",
        "### Outline\n",
        "- System Selection\n",
        "- \n",
        "- Model Testing\n",
        "    - Train \n",
        "    - \n",
        "- Inference with Custom Model\n",
        "- Evaluation\n",
        "- Future Improvements\n",
        "\n",
        "The results of this code are accompanied in the following [Report](REport)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## System Selection and Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyRdDYkqAKN4"
      },
      "source": [
        "\n",
        "The selection test models are **YOLOv8, RT-DETR, YOLO-NAS ** based on:\n",
        "- State of Art (speed and acccuracy)\n",
        "- Reasonable Computational Requirements\n",
        "- Edge Deployment Scnearios (Jetson platforms) \n",
        "\n",
        "### Preprocessing\n",
        "Using Roboflows Dataset tool I apply the following preprocessing.\n",
        "\n",
        "    1. Auto-Orient\n",
        "    2. Resize (Strectch 640x640)\n",
        "    3. Auto-Adjust Contrast (Using Adaptive Equalization)\n",
        "    4. Grayscale\n",
        "#3 Augementation\n",
        "Creating augmented version fo each image in training set by **By applying Horizontal Flip, and Vertical Flip**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## YOLOv8 Test\n",
        "\n",
        "Is a state of the art with reasonable computational requirements, speed, and accuracy. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cjs/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
            "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current working directory: /home/cjs/Documents/Probe-Detection-Using-Deep-Learning/notebook\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: ultralytics in /home/cjs/.local/lib/python3.10/site-packages (8.2.103)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /home/cjs/.local/lib/python3.10/site-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /home/cjs/.local/lib/python3.10/site-packages (from ultralytics) (2.5.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /home/cjs/.local/lib/python3.10/site-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /home/cjs/.local/lib/python3.10/site-packages (from ultralytics) (2.0.13)\n",
            "Requirement already satisfied: requests>=2.23.0 in /home/cjs/.local/lib/python3.10/site-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /home/cjs/.local/lib/python3.10/site-packages (from ultralytics) (0.20.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /home/cjs/.local/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /home/cjs/.local/lib/python3.10/site-packages (from ultralytics) (2.2.3)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /home/cjs/.local/lib/python3.10/site-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /home/cjs/.local/lib/python3.10/site-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: psutil in /usr/lib/python3/dist-packages (from ultralytics) (5.9.0)\n",
            "Requirement already satisfied: py-cpuinfo in /home/cjs/.local/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /home/cjs/.local/lib/python3.10/site-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /home/cjs/.local/lib/python3.10/site-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /home/cjs/.local/lib/python3.10/site-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/lib/python3/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.29.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/lib/python3/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/cjs/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/cjs/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/cjs/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/cjs/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.1.4->ultralytics) (2022.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/cjs/.local/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/cjs/.local/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.20)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/cjs/.local/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/cjs/.local/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.23.0->ultralytics) (2020.6.20)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/cjs/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/cjs/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/cjs/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: triton==3.1.0 in /home/cjs/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /home/cjs/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/cjs/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/cjs/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/cjs/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/cjs/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: networkx in /home/cjs/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/cjs/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/cjs/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: fsspec in /home/cjs/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/cjs/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/cjs/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: filelock in /home/cjs/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/cjs/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/cjs/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/cjs/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'function' object has no attribute 'clear_output'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_65243/3931676139.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Clear any residual outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Verify YOLO setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'clear_output'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "from IPython import display\n",
        "from IPython.display import display, Image\n",
        "\n",
        "# Set up home directory\n",
        "HOME = os.getcwd()\n",
        "print(f\"Current working directory: {HOME}\")\n",
        "\n",
        "# Install required library (ensure ultralytics is installed)\n",
        "!pip install ultralytics\n",
        "\n",
        "# Clear any residual outputs\n",
        "display.clear_output()\n",
        "\n",
        "# Verify YOLO setup\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "\n",
        "# Ensure dataset directory exists\n",
        "datasets_path = os.path.join(HOME, 'data/probe_preprocessed_YOLOv8')\n",
        "os.makedirs(datasets_path, exist_ok=True)\n",
        "\n",
        "# Change directory to datasets (if needed)\n",
        "os.chdir(datasets_path)\n",
        "print(f\"Dataset directory: {os.getcwd()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "# HOME = os.getcwd()\n",
        "# print(HOME)\n",
        "\n",
        "# !pip install ultralytics\n",
        "\n",
        "# from IPython import display\n",
        "# display.clear_output()\n",
        "\n",
        "# import ultralytics\n",
        "# ultralytics.checks()\n",
        "# from ultralytics import YOLO\n",
        "\n",
        "# from IPython.display import display, Image\n",
        "\n",
        "# !mkdir -p {HOME}/datasets\n",
        "# %cd {HOME}/datasets\n",
        "\n",
        "# !pip install roboflow\n",
        "\n",
        "# # ~~~~~~~~~~~~~~~  CONNECTION TO ROBOFLOW  ~~~~~~~~~~~~~~~\n",
        "# # !pip install roboflow\n",
        "\n",
        "# # from roboflow import Roboflow\n",
        "# # rf = Roboflow(api_key=\"VBCtrUJMVNVKifV2CuOl\")\n",
        "# # project = rf.workspace(\"julien-xkm5o\").project(\"probe-detection-fly\")\n",
        "# # version = project.version(1)\n",
        "# # dataset = version.download(\"yolov8\")\n",
        "                "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train YOLOv8 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize YOLO model and train with the local dataset\n",
        "model = YOLO('yolov8s.pt')  # Change 'yolov8n.pt' to the desired YOLOv8 variant\n",
        "model.train(data=f\"{datasets_path}/data.yaml\", epochs=50, batch=16, imgsz=640)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# %cd {HOME}\n",
        "\n",
        "# !yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=50 imgsz=800 plots=True\n",
        "                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !ls {HOME}/runs/detect/train\n",
        "!ls {HOME}/data/probe_preprocessed_YOLOv8/runs/detect/train3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %cd {HOME}\n",
        "# Image(filename=f'{HOME}/runs/detect/train/confusion_matrix.png', width=1000)\n",
        "Image(filename=f'{HOME}/data/probe_preprocessed_YOLOv8/runs/detect/train3/confusion_matrix.png', width=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %cd {HOME}\n",
        "# Image(filename=f'{HOME}/runs/detect/train/results.png', width=1000)\n",
        "Image(filename=f'{HOME}/data/probe_preprocessed_YOLOv8/runs/detect/train3/results.png', width=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %cd {HOME}\n",
        "# Image(filename=f'{HOME}/runs/detect/train/val_batch0_pred.jpg', width=1000)\n",
        "Image(filename=f'{HOME}/data/probe_preprocessed_YOLOv8/runs/detect/train3/val_batch0_pred.jpg', width=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validate Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate model\n",
        "model.val()\n",
        "\n",
        "# %cd {HOME}\n",
        "\n",
        "# !yolo task=detect mode=val model={HOME}/runs/detect/train/weights/best.pt data={dataset.location}/data.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inference with Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "!yolo task=detect mode=predict model={HOME}/runs/detect/train/weights/best.pt conf=0.25 source={dataset.location}/test/images save=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Look at some example test results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "\n",
        "# Define the base path where the folders are located\n",
        "base_path = f\"{HOME}/runs/detect/\"\n",
        "\n",
        "    \n",
        "# List all directories that start with 'predict' in the base path\n",
        "subfolders = [os.path.join(base_path, d) for d in os.listdir(base_path)\n",
        "              if os.path.isdir(os.path.join(base_path, d)) and d.startswith('predict')]\n",
        "\n",
        "# Find the latest folder by modification time\n",
        "latest_folder = max(subfolders, key=os.path.getmtime)\n",
        "\n",
        "image_paths = glob.glob(f'{latest_folder}/*.jpg')[:4]\n",
        "\n",
        "# Display each image\n",
        "for image_path in image_paths:\n",
        "    display(Image(filename=image_path, width=600))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZRK3zxS2m1n"
      },
      "source": [
        "# Deploy Your Model to the Edge\n",
        "\n",
        "In addition to using the Roboflow hosted API for deployment, you can use [Roboflow Inference](https://inference.roboflow.com), an open source inference solution that has powered millions of API calls in production environments. Inference works with CPU and GPU, giving you immediate access to a range of devices, from the NVIDIA Jetson to TRT-compatible devices to ARM CPU devices.\n",
        "\n",
        "With Roboflow Inference, you can self-host and deploy your model on-device. You can deploy applications using the [Inference Docker containers](https://inference.roboflow.com/quickstart/docker/) or the pip package.\n",
        "\n",
        "For example, to install Inference on a device with an NVIDIA GPU, we can use:\n",
        "\n",
        "```\n",
        "docker pull roboflow/roboflow-inference-server-gpu\n",
        "```\n",
        "\n",
        "Then we can run inference via HTTP:\n",
        "\n",
        "```python\n",
        "import requests\n",
        "\n",
        "workspace_id = \"\"\n",
        "model_id = \"\"\n",
        "image_url = \"\"\n",
        "confidence = 0.75\n",
        "api_key = \"\"\n",
        "\n",
        "infer_payload = {\n",
        "    \"image\": {\n",
        "        \"type\": \"url\",\n",
        "        \"value\": image_url,\n",
        "    },\n",
        "    \"confidence\": confidence,\n",
        "    \"iou_threshold\": iou_thresh,\n",
        "    \"api_key\": api_key,\n",
        "}\n",
        "res = requests.post(\n",
        "    f\"http://localhost:9001/{workspace_id}/{model_id}\",\n",
        "    json=infer_object_detection_payload,\n",
        ")\n",
        "\n",
        "predictions = res.json()\n",
        "```\n",
        "\n",
        "Above, set your Roboflow workspace ID, model ID, and API key.\n",
        "\n",
        "- [Find your workspace and model ID](https://docs.roboflow.com/api-reference/workspace-and-project-ids?ref=blog.roboflow.com)\n",
        "- [Find your API key](https://docs.roboflow.com/api-reference/authentication?ref=blog.roboflow.com#retrieve-an-api-key)\n",
        "\n",
        "Also, set the URL of an image on which you want to run inference. This can be a local file.\n",
        "\n",
        "_To use your YOLOv5 model commercially with Inference, you will need a Roboflow Enterprise license, through which you gain a pass-through license for using YOLOv5. An enterprise license also grants you access to features like advanced device management, multi-model containers, auto-batch inference, and more._"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "usr",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
